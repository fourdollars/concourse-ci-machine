jobs:
- name: benchmark-cpu
  plan:
  - get: benchmark-cpu-trigger
    trigger: true
  - task: matrix-multiply-cpu
    timeout: 5m
    tags: [gpu]
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: python
          tag: 3.11-slim
      run:
        path: sh
        args:
        - -c
        - |
          echo "=============================="
          echo "CPU Benchmark - Matrix Multiply"
          echo "=============================="
          pip install --quiet numpy
          
          python3 << 'EOF'
          import numpy as np
          import time
          
          print("Testing CPU performance...")
          print("Matrix size: 5000x5000")
          print()
          
          # Create large matrices
          np.random.seed(42)
          A = np.random.rand(5000, 5000).astype(np.float32)
          B = np.random.rand(5000, 5000).astype(np.float32)
          
          # Warm-up
          _ = np.dot(A[:100, :100], B[:100, :100])
          
          # Benchmark
          iterations = 3
          times = []
          
          for i in range(iterations):
              start = time.time()
              C = np.dot(A, B)
              end = time.time()
              elapsed = end - start
              times.append(elapsed)
              print(f"Iteration {i+1}: {elapsed:.3f} seconds")
          
          avg_time = sum(times) / len(times)
          gflops = (2 * 5000**3) / avg_time / 1e9
          print()
          print(f"Average time: {avg_time:.3f} seconds")
          print(f"Performance: {gflops:.2f} GFLOPS")
          print()
          
          # Write results to shared folder
          try:
              with open("/srv/benchmark_rw_writable/cpu_result.txt", "w") as f:
                  f.write(f"{avg_time:.3f},{gflops:.2f}")
              print("✓ Results saved to shared folder")
          except Exception as e:
              print(f"⚠ Failed to save results: {e}")
              
          print("✓ CPU benchmark complete")
          EOF

- name: benchmark-gpu
  plan:
  - get: benchmark-gpu-trigger
    trigger: true
  - task: matrix-multiply-gpu
    timeout: 5m
    tags: [gpu]
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: pytorch/pytorch
          tag: 2.1.0-cuda12.1-cudnn8-runtime
      run:
        path: sh
        args:
        - -c
        - |
          echo "=============================="
          echo "GPU Benchmark - Matrix Multiply"
          echo "=============================="
          echo "GPU Info:"
          nvidia-smi --query-gpu=name,memory.total,driver_version --format=csv,noheader
          echo
          
          python3 << 'EOF'
          import torch
          import time
          
          if not torch.cuda.is_available():
              print("ERROR: CUDA not available!")
              exit(1)
          
          print(f"Using GPU: {torch.cuda.get_device_name(0)}")
          print(f"CUDA Version: {torch.version.cuda}")
          print("Matrix size: 5000x5000")
          print()
          
          # Create large matrices on GPU
          torch.manual_seed(42)
          A = torch.randn(5000, 5000, dtype=torch.float32).cuda()
          B = torch.randn(5000, 5000, dtype=torch.float32).cuda()
          
          # Warm-up
          _ = torch.matmul(A[:100, :100], B[:100, :100])
          torch.cuda.synchronize()
          
          # Benchmark
          iterations = 3
          times = []
          
          for i in range(iterations):
              torch.cuda.synchronize()
              start = time.time()
              C = torch.matmul(A, B)
              torch.cuda.synchronize()
              end = time.time()
              elapsed = end - start
              times.append(elapsed)
              print(f"Iteration {i+1}: {elapsed:.3f} seconds")
          
          avg_time = sum(times) / len(times)
          gflops = (2 * 5000**3) / avg_time / 1e9
          print()
          print(f"Average time: {avg_time:.3f} seconds")
          print(f"Performance: {gflops:.2f} GFLOPS")
          print()
          
          # Write results to shared folder
          try:
              with open("/srv/benchmark_rw_writable/gpu_result.txt", "w") as f:
                  f.write(f"{avg_time:.3f},{gflops:.2f}")
              print("✓ Results saved to shared folder")
          except Exception as e:
              print(f"⚠ Failed to save results: {e}")
              
          print("✓ GPU benchmark complete")
          EOF

- name: benchmark-comparison
  plan:
  - get: benchmark-cpu-trigger
    trigger: true
    passed: [benchmark-cpu]
  - get: benchmark-gpu-trigger
    trigger: true
    passed: [benchmark-gpu]
  - task: summary
    tags: [gpu]
    timeout: 1m
    config:
      platform: linux
      image_resource:
        type: registry-image
        source:
          repository: python
          tag: 3.11-slim
      run:
        path: python3
        args:
        - -c
        - |
          import os
          
          print("============================================")
          print("     CPU vs GPU Benchmark Comparison")
          print("============================================")
          print()
          
          cpu_file = "/srv/benchmark_rw_writable/cpu_result.txt"
          gpu_file = "/srv/benchmark_rw_writable/gpu_result.txt"
          
          cpu_data = None
          gpu_data = None
          
          if os.path.exists(cpu_file):
              try:
                  with open(cpu_file, "r") as f:
                      parts = f.read().strip().split(",")
                      if len(parts) == 2:
                          cpu_data = {"time": float(parts[0]), "gflops": float(parts[1])}
              except Exception as e:
                  print(f"Error reading CPU results: {e}")
          
          if os.path.exists(gpu_file):
              try:
                  with open(gpu_file, "r") as f:
                      parts = f.read().strip().split(",")
                      if len(parts) == 2:
                          gpu_data = {"time": float(parts[0]), "gflops": float(parts[1])}
              except Exception as e:
                  print(f"Error reading GPU results: {e}")
          
          print(f"{'Metric':<15} {'CPU':<15} {'GPU':<15} {'Speedup':<15}")
          print("-" * 60)
          
          if cpu_data and gpu_data:
              print(f"{'Time (s)':<15} {cpu_data['time']:<15.3f} {gpu_data['time']:<15.3f} {cpu_data['time']/gpu_data['time']:.1f}x")
              print(f"{'GFLOPS':<15} {cpu_data['gflops']:<15.2f} {gpu_data['gflops']:<15.2f} {gpu_data['gflops']/cpu_data['gflops']:.1f}x")
          else:
              if cpu_data:
                  print(f"{'Time (s)':<15} {cpu_data['time']:<15.3f} {'-':<15} {'-':<15}")
                  print(f"{'GFLOPS':<15} {cpu_data['gflops']:<15.2f} {'-':<15} {'-':<15}")
              
              if not cpu_data:
                  print("Missing CPU benchmark results.")
              if not gpu_data:
                  print("Missing GPU benchmark results.")
              
          print()

resources:
- name: benchmark-cpu-trigger
  type: time
  source: {interval: 24h}
- name: benchmark-gpu-trigger
  type: time
  source: {interval: 24h}
